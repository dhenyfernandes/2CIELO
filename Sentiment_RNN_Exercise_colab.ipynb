{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ7Nr_rfEUfn"
   },
   "source": [
    "# Análise de Sentimento com uma RNN\n",
    "\n",
    "Neste notebook, você irá implementar uma RNN que realiza análise de sentimentos.\n",
    ">Usar uma RNN ao invés de uma rede estritamente feedforward é mais acurado visto que podemos incluir informações sobre a *sequência* de palavras.\n",
    "\n",
    "Aqui, vamos usar um dataset de review de filmes, acompanhado por um rótulo de sentimento: positivo ou negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "N4el186NEUfo",
    "outputId": "a8152c06-e522-4277-d933-d79c4bb51628"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(open('assets/reviews_ex.png','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHKNXmWfEUfq"
   },
   "source": [
    "### Arquitetura da Rede\n",
    "\n",
    "A Arquitetura da rede é mostrada abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "jGC01ylMEUfq",
    "outputId": "5e623250-8dfe-423a-c750-034951cc77e6"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(open('assets/network_diagram.png','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3P_2BS_EUfq"
   },
   "source": [
    ">**Primeiro, vamos passar as palavras numa camada de embedding.** Precisamos de uma camada de embedding visto que temos milhares de palavras, então precisamos de uma representação eficiente que os vetores one-hot encode para nosso input de dados. Podemos treinar um modelo Word2Vec e usar esses embeddings como input. Entretanto, é interessante ter uma camada de embedding e deixar a rede aprender a tabela de embedding por conta própria. *Neste caso, a camada de embedding é para redução de dimensionalidade ao invés de ser para aprendizado de representação semântica.*\n",
    "\n",
    ">**Depois, os inputs (palavras) são passados para uma camada de embeddings e os novos embeddings serão passados para células LSTM.** As células LSTM irão adicionar conexões *recorrentes* a rede e fornecer a habilidade de incluir informação sobre a *sequência* de palavras nos dados de review.\n",
    "\n",
    ">**Finalmente, a saída da LSTM passará para uma sigmoide na camada de saída.** Estamos usando a função sigmoide porque tratamos positivo como 1 e negativo como 0 e a sigmoide produzirá valores entre 0-1.\n",
    "\n",
    "Não nos preocuparemos com as saídas da sigmoide exceto pela **última**; podemos ignorar as demais. Iremos calcular a loss comparando o output no último instante de tempo e o rótulo da amostra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYKqh4vDEUfq"
   },
   "source": [
    "---\n",
    "### Carregar e visualizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnN6cyTCEUfr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# read data from text files\n",
    "with open('data/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('data/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNln3ZM3EUfr",
    "outputId": "fdc8e6ae-e1b5-4e02-c69b-91ba230ac066"
   },
   "outputs": [],
   "source": [
    "print(reviews[:1000])\n",
    "print()\n",
    "print(labels[:18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XRoRfVEEUfr"
   },
   "source": [
    "## Pré-processamento dos Dados\n",
    "\n",
    "O primeiro passo ao construir um modelo de rede neural é colocar seus dados no formato adequado para input na rede. Visto que estamos usando camadas embedding, precisaremos encodar cada palavra como um inteiro. Vamos precisar também realizar alguma limpeza.\n",
    "\n",
    "Estes são os passos do pré-processamento:\n",
    "\n",
    ">* Queremos eliminar pontos e pontuações estranhas.\n",
    "* Além disso, você pode ter notado que os reviews são delimitados com o caracter de nova linha `\\n`. Para lidar com isso, vamos separar o texto em cada review usando `\\n` como delimitador\n",
    "* Então vamos combinar todos os reviews de volta numa única grande string.\n",
    "\n",
    "Primeiro, vamos remover toda pontuação. Em seguida, pegue todo o texto sem novas linhas e divida-o em palavras individuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_5gYVBxEUfr"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# get rid of punctuation\n",
    "reviews = reviews.lower() # lowercase, standardize\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "\n",
    "# split by new lines and spaces\n",
    "reviews_split = all_text.split('\\n')\n",
    "all_text = ' '.join(reviews_split)\n",
    "\n",
    "# create a list of words\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Df-7o4X1EUfr",
    "outputId": "7dd5d949-ffff-4505-a076-9d6bdb383514"
   },
   "outputs": [],
   "source": [
    "words[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWTr5CfvEUfs"
   },
   "source": [
    "### Codificando as palavras\n",
    "\n",
    "A tabela de embedding requer que passemos números inteiros para nossa rede. A maneira mais fácil de fazer isso é criar dicionários que mapeiem as palavras do vocabulário para números inteiros. Em seguida, podemos converter cada um de nossos reviews em números inteiros para que possam ser transmitidas à rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mi-sSmAsEUfs"
   },
   "outputs": [],
   "source": [
    "# feel free to use this import\n",
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary that maps words to integers\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "## use the dict to tokenize each review in reviews_split\n",
    "## store the tokenized reviews in reviews_ints\n",
    "reviews_ints = []\n",
    "for review in reviews_split:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhP3zyM5EUfs"
   },
   "source": [
    "**Testando**\n",
    "\n",
    "Como um texto que você implementou o dicionário corretamente, imprima o número de palavras únicas em seu vocabulário e o conteúdo da primeira revisão tokenizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utIcVabYEUfs",
    "outputId": "c23b5bbb-e6d6-46c3-cc5b-0a52f580ca6b"
   },
   "outputs": [],
   "source": [
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
    "print()\n",
    "\n",
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', reviews_ints[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-fTOVC0EUfs"
   },
   "source": [
    "### Codificando as labels\n",
    "\n",
    "Nossos rótulos são “positivos” ou “negativos”. Para usar esses rótulos em nossa rede, precisamos convertê-los para 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hguzrG8gEUfs"
   },
   "outputs": [],
   "source": [
    "# 1=positive, 0=negative label conversion\n",
    "labels_split = labels.split('\\n')\n",
    "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qvKtQj7EUfs"
   },
   "source": [
    "### Removendo Outliers\n",
    "\n",
    "Como uma etapa adicional de pré-processamento, queremos ter certeza de que nossos reviews estão em um bom formato para o processamento padrão. Ou seja, nossa rede espera um tamanho de texto de entrada padrão e, portanto, queremos moldar nossos reviews em um comprimento específico. Abordaremos esta tarefa em duas etapas principais:\n",
    "\n",
    "1. Livrar-se de reviews extremamente longos ou curtos; os outliers\n",
    "2. Preencher/truncar (padding) os dados restantes para que tenhamos reviews do mesmo tamanho.\n",
    "\n",
    "Before we pad our review text, we should check for reviews of extremely short or long lengths; outliers that may mess with our training.\n",
    "Antes de preenchermos nosso review, devemos verificar se há reviews de comprimento extremamente curto ou longo; valores discrepantes que podem atrapalhar nosso treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDliB604EUft",
    "outputId": "86d8401d-6aa5-4436-a2cf-d99bd9c1e129"
   },
   "outputs": [],
   "source": [
    "# outlier review stats\n",
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbxqQSyWEUft"
   },
   "source": [
    "Ok, alguns problemas aqui. Parece que temos um review com comprimento zero. E há um review muito grande para nossa RNN. Teremos que remover quaisquer reviews supercurtos e truncar reviews superlongos. Isso remove valores discrepantes e deve permitir que nosso modelo seja treinado com mais eficiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSTAfH-KEUft",
    "outputId": "9378d23e-5592-4dfa-d4d2-2d2e046c79fe"
   },
   "outputs": [],
   "source": [
    "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
    "\n",
    "## remove any reviews/labels with zero length from the reviews_ints list.\n",
    "\n",
    "# get indices of any reviews with length 0\n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "\n",
    "# remove 0-length reviews and their labels\n",
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
    "\n",
    "print('Number of reviews after removing outliers: ', len(reviews_ints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsR-KNG5EUft"
   },
   "source": [
    "---\n",
    "## Padding sequences - ToDo 1\n",
    "\n",
    "Para lidar tanto com reviews curtos quanto os muito grandes vamos preencher or truncar todos os reviews para um tamanho específico. Para reviews pequenos que uma determinada `seq_length`, vamos preencher com 0s. Para reviews maiores que `seq_length`, vamos truncar até o tamanho `seq_length`, que, neste caso é 200.\n",
    "\n",
    "* Os dados devem vir de `review_ints`, visto que vamos alimentar a rede com números inteiros.\n",
    "* Cada linha deve possuir comprimento igual a `seq_length`\n",
    "* para reviews menores que `seq_length` palavras, preencha à esquerda com 0s (padding). Ex: se o review é `['best', 'movie', 'ever']`, ou `[117, 18, 128]` como inteiros, aplicando o padding o review será `[0, 0, 0, ..., 0, 117, 18, 128]`.\n",
    "* Para reviews maiores que `seq_length`, use apenas as primeiras `seq_length` palavras.\n",
    "\n",
    "Como um pequeno exemplo, se `seq_length=10` e review de input é\n",
    "```\n",
    "[117, 18, 128]\n",
    "```\n",
    "O vetor resultando, depois de aplicado o padding, deverá ser:\n",
    "```\n",
    "[0, 0, 0, 0, 0, 0, 0, 117, 18, 128]\n",
    "```\n",
    "**Seu array final `features` deve ser um array 2D, com o número de linhas iguais ao número de reviews e o número de colunas igual ao especificado em `seq_length`.**\n",
    "\n",
    "Isto não é trivial e existem muitas maneiras de fazer isso, mas se você irá construir suas próprias redes Deep Learning, você terá que se acostumar a preparar os seus dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtZf3tz1EUft"
   },
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    '''\n",
    "    Retorna features de reviews_ints, em que cada review é preenchido com 0s ou truncado até o tamanho de seq_length\n",
    "\n",
    "    Dicas: crie uma matriz de tamanho mxn, em que m é a quantidade de reviews e n é seq_length e a preencha com zeros.\n",
    "    Depois, percorra as linhas dessa matriz, capturando o tamanho de cada review (linha) e preencha, da ultima coluna para a primeira, com os reviews\n",
    "    '''\n",
    "\n",
    "    #START CODE HERE\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cR-qw5UBEUft",
    "outputId": "13880d9f-c397-4c92-b777-5a843c1f68bd"
   },
   "outputs": [],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "seq_length = 200\n",
    "\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches\n",
    "print(features[:30,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTJ7pLadEUfu"
   },
   "source": [
    "## Training, Validation, Test\n",
    "## Treino, Validação e Teste\n",
    "\n",
    "Com os dados no formato correto, vamos dividi-lo em conjunto de treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zs2T211OEUfu",
    "outputId": "6b839fe7-c265-4c40-c783-f81504ef5501"
   },
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwFutZRjEUfu"
   },
   "source": [
    "**Check your work**\n",
    "\n",
    "With train, validation, and test fractions equal to 0.8, 0.1, 0.1, respectively, the final, feature data shapes should look like:\n",
    "```\n",
    "                    Feature Shapes:\n",
    "Train set: \t\t (20000, 200)\n",
    "Validation set: \t(2500, 200)\n",
    "Test set: \t\t  (2500, 200)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_R4ioU2_EUfu"
   },
   "source": [
    "---\n",
    "## DataLoaders e Batching\n",
    "\n",
    "Depois de criar os conjuntos de treino, validação e teste, podemos criar os DataLoaders seguindos os seguintes passos:\n",
    "\n",
    "1. Crie um formato para acessar nosso dados usando [TensorDataset](https://pytorch.org/docs/stable/data.html#) que toma como input um conjunto de dados e um conjunto de labels\n",
    "2. Crie DataLoaders a partir dos Tensor datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WBOSGGJEUfu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Jw_pTLCEUfu",
    "outputId": "1463b1a6-a29c-48c9-c67d-a08543028bfe"
   },
   "outputs": [],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qPlkLl-EUfu"
   },
   "source": [
    "# Definição da Rede para análise de sentimento usando PyTorch - ToDo 2\n",
    "\n",
    "Essa é a arquitetura da rede que vamos definir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "9OOROT3CEUfu",
    "outputId": "f0a7a549-d621-4fe6-f8ae-89579713d15c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(open('assets/network_diagram.png','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4MwjGboEUfv"
   },
   "source": [
    "---\n",
    "As camadas são as seguintes:\n",
    "1. Uma [camada embedding](https://pytorch.org/docs/stable/nn.html#embedding) que converte tokens de palavras (inteiros) em embeddings de tamanho específico.\n",
    "2. Uma [camada LSTM](https://pytorch.org/docs/stable/nn.html#lstm) definida por um tamanho hidden_state e um número de camadas\n",
    "3. uma camada de saída totalmente conectada que mapeia a saída da camada LSTM para um tamanho desejado\n",
    "4. Uma camada com função de ativação sigmoide que transforma todos os outputs num valor 0-1; retorne **apenas a última saída da sigmoide** como saída da rede\n",
    "\n",
    "\n",
    "### A camada de Embedding\n",
    "\n",
    "Nós precisamos de uma camada de embedding porque temos mais de 74000 palavras em nosso vocabulário. É extremamente ineficiente fazer one-hot encoding desse valor e, por isso, criamos uma camada embedding que funcionará como uma tabela de pesquisa. Poderíamos treinar uma camada usando Word2Vec e usá-la aqui, mas é adequado criar uma nova camada, com o propósito de reduçãoo de dimensionalidade, e deixar a rede aprender os pesos.\n",
    "\n",
    "\n",
    "### A camada LSTM\n",
    "\n",
    "Vamos criar uma camada LSTM para usar em nossa rede recorrente, que toma um input_size, um hidden_dim e um número de camadas, uma probabilidade de dropout e um batch_first como parametros.\n",
    "\n",
    "\n",
    "> **Exercício:** Complete as funções `__init__`, `forward`, e `init_hidden` na classe SentimentRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Lpdf9vtEUfv",
    "outputId": "a853710c-18f1-4aaf-bb04-520f06f6585c"
   },
   "outputs": [],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb5ViF-eEUfv"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = \n",
    "        self.n_layers = \n",
    "        self.hidden_dim = \n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = \n",
    "        self.lstm = \n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = \n",
    "\n",
    "        # linear and sigmoid layers\n",
    "        self.fc = \n",
    "        self.sig = \n",
    "\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = \n",
    "        lstm_out, hidden = \n",
    "\n",
    "        lstm_out = lstm_out[:, -1, :] # getting the last time step output\n",
    "\n",
    "        # dropout and fully-connected layer\n",
    "        out = \n",
    "        out = \n",
    "        # sigmoid function\n",
    "        sig_out = \n",
    "\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCt0KD1hEUfv"
   },
   "source": [
    "## Instancie a Rede\n",
    "\n",
    "Aqui, vamos instanciar a rede. Primeiro, vamos definir os hiperparâmetros.\n",
    "\n",
    "\n",
    "* `vocab_size`: Tamanho do vocabulário\n",
    "* `output_size`: Tamanho do output desejado\n",
    "* `embedding_dim`: tamanho dos nossos embeddings\n",
    "* `hidden_dim`: Número de neurônios na camada oculta. Geralmente 128, 256, 512, etc.\n",
    "* `n_layers`: Número de camadas LSTM. Tipicamente entre 1-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcWLEiVbEUfv",
    "outputId": "83c99855-2354-4aa2-b65e-81f80d17adb0"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wo_1pCmYEUfv"
   },
   "source": [
    "---\n",
    "## Treino\n",
    "\n",
    "Abaixo está um típico código para treino. Vamos usar um tipo de loss que foi projetada para trabalhar com um único output da Sigmoide. [BCELoss](https://pytorch.org/docs/stable/nn.html#bceloss), ou **Binary Cross Entropy Loss**, aplica a loss cross entropy a um único valor entre 0 e 1.\n",
    "\n",
    "Temos também alguns hiperparametros:\n",
    "\n",
    "* `lr`: Learning rate\n",
    "* `epochs`: Número de vezes a iterar sobre todo dataset.\n",
    "* `clip`: O valor máximo de gradiente para corte (para prevenir explosão do gradiente) [link](https://machinelearningmastery.com/exploding-gradients-in-neural-networks/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9HYoYeMEUfv"
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2FTQQipEUfw",
    "outputId": "b1baea3b-5e23-4794-becd-d03fece30aee"
   },
   "outputs": [],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ys3sipPEUfw"
   },
   "source": [
    "---\n",
    "## Teste\n",
    "\n",
    "Exsitem algumas maneiras de testar nossa rede.\n",
    "\n",
    "* **Performance no conjunto de teste:** Primeiro, veremos como nosso modelo treinado performa no conjunto de teste. Vamos calcular a loss e acurácia média.\n",
    "\n",
    "* **Inferência em dados gerados pelo usuário:** Segundo, veremos como nosso modelo responde um review por vez (sem o rótulo) e analisaremos qual a predição do modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBIjVjCxEUfw",
    "outputId": "57145cb0-fc3a-47ae-e3ff-9fe2858ac052"
   },
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "\n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "\n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tGN741jEUfw"
   },
   "source": [
    "### Inferência num review de teste\n",
    "\n",
    "Você pode alterar o review para qualquer texto que queira. Leia-o e pense: é um review positivo ou negativo? Então veja se o seu modelo faz a predição correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVD02abCEUfw"
   },
   "outputs": [],
   "source": [
    "# negative test review\n",
    "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0K7vKqBEUfw",
    "outputId": "76fce7af-f575-4435-dab0-dcac615fb3d7"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def tokenize_review(test_review):\n",
    "    test_review = test_review.lower() # lowercase\n",
    "    # get rid of punctuation\n",
    "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "\n",
    "    # splitting by spaces\n",
    "    test_words = test_text.split()\n",
    "\n",
    "    # tokens\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int.get(word, 0) for word in test_words])\n",
    "\n",
    "    return test_ints\n",
    "\n",
    "# test code and generate tokenized review\n",
    "test_ints = tokenize_review(test_review_neg)\n",
    "print(test_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VI8I5dVzEUfx",
    "outputId": "4b517243-dc86-4826-ae3d-79fbf04f119a"
   },
   "outputs": [],
   "source": [
    "# test sequence padding\n",
    "seq_length=200\n",
    "features = pad_features(test_ints, seq_length)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HnxLvK3EUfx",
    "outputId": "de8f9b77-2389-4989-84a6-7bdb139a0bd1"
   },
   "outputs": [],
   "source": [
    "# test conversion to tensor and pass into your model\n",
    "feature_tensor = torch.from_numpy(features)\n",
    "print(feature_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCY72gNaEUfx"
   },
   "outputs": [],
   "source": [
    "def predict(net, test_review, sequence_length=200):\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    # tokenize review\n",
    "    test_ints = tokenize_review(test_review)\n",
    "\n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "\n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "\n",
    "    batch_size = feature_tensor.size(0)\n",
    "\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "\n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor, h)\n",
    "\n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())\n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "\n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpIQfGOZEUfx"
   },
   "outputs": [],
   "source": [
    "# positive test review\n",
    "test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwWCq_J-EUfx",
    "outputId": "91db5c91-7512-4993-9738-16990fe21ef3"
   },
   "outputs": [],
   "source": [
    "# call function\n",
    "seq_length=200 # good to use the length that was trained on\n",
    "\n",
    "predict(net, test_review_neg, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfSLbwIHH5bI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
